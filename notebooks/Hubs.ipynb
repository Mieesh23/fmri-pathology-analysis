{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85dfdc56-63d5-459f-b1d9-9af93caaf457",
   "metadata": {},
   "source": [
    "### Graph Theory Hubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94eeb604-3ccd-4883-8724-be8feba4e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "115ed2c2-34db-4bb8-8499-6e826a5297a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "def filter_strings_not_in_list(strings_list, substrings_list):\n",
    "    filtered_list = []\n",
    "    for s in strings_list:\n",
    "        if not any(substring in s for substring in substrings_list):\n",
    "            filtered_list.append(s)\n",
    "    return filtered_list\n",
    "folder_path = '/path_to/ROISignals_FunImgARCWF'  # Pfad zum Ordner\n",
    "strings_list = []\n",
    "for file_name in os.listdir(folder_path):\n",
    "    strings_list.append(file_name)\n",
    "with open('/path_to/data_tools/first_id_list.pkl', 'rb') as file:\n",
    "    data_list_substrings = pickle.load(file)\n",
    "\n",
    "filtered_list = filter_strings_not_in_list(strings_list, data_list_substrings)\n",
    "print(len(filtered_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b499bc12-e6c6-4dc1-8a80-9b384a3652de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "\n",
    "for j, file_name in enumerate(filtered_list[:1300]):\n",
    "    \n",
    "    degree_list = []\n",
    "    betweenness_list = []\n",
    "    clustering_list = []\n",
    "    closeness_list = []\n",
    "    hubs_score =[]\n",
    "    \n",
    "    mat = scipy.io.loadmat(os.path.join(folder_path, file_name))\n",
    "    matrix = mat['ROISignals']\n",
    "\n",
    "    aal_array = matrix[:, :116]  # 1~116: Automated Anatomical Labeling (AAL) atlas (Tzourio-Mazoyer et al., 2002)\n",
    "    #hoac_array = matrix[:, 116:212]   # 117~212: Harvard-Oxford atlas (Kennedy et al., 1998)– cortical areas\n",
    "    #hoas_array = matrix[:, 212:228]   # 213~228: Harvard-Oxford atlas (Kennedy et al., 1998)– subcortical areas\n",
    "    #ccl_array = matrix[:, 228:428]    # 229~428: Craddock’s clustering 200 ROIs (Craddock et al., 2012)\n",
    "    #zrp_array = matrix[:, 428:1408]   # 429~1408: Zalesky’s random parcelations (compact version: 980 ROIs) (Zalesky et al., 2010)\n",
    "    #dbf_array = matrix[:, 1408:1568]  # 1409~1568: Dosenbach’s 160 functional ROIs (Dosenbach et al., 2010)\n",
    "\n",
    "    correlation_measure = ConnectivityMeasure(kind='correlation')\n",
    "    correlation_matrix = correlation_measure.fit_transform([aal_array])[0]\n",
    "\n",
    "    threshold = 0.35  \n",
    "    twenties = 23 \n",
    " \n",
    "    thresholded_matrix = np.where(correlation_matrix >= threshold, 1, 0)\n",
    "    np.fill_diagonal(thresholded_matrix, 0)\n",
    "    graph = nx.from_numpy_array(thresholded_matrix)\n",
    "\n",
    "    label = int(file_name.split('-')[1])\n",
    "\n",
    "    # degree model\n",
    "    degree_ = nx.degree(graph)\n",
    "    degree = dict(degree_).values()\n",
    "    \n",
    "    # Betweenness Centrality\n",
    "    betweenness = nx.betweenness_centrality(graph).values()\n",
    "\n",
    "    # Clustering Coefficient\n",
    "    clustering = nx.clustering(graph).values()\n",
    "    \n",
    "    # Closeness Centrality\n",
    "    closeness = nx.closeness_centrality(graph).values()\n",
    "\n",
    "    # Sort values\n",
    "    sorted_degree = sorted(degree, reverse=True)\n",
    "    sorted_betweenness = sorted(betweenness, reverse=True)\n",
    "    sorted_clustering = sorted(clustering)\n",
    "    sorted_closeness = sorted(closeness, reverse=True)\n",
    "\n",
    "    num_values_to_set = 23\n",
    "    result_degree = [1 if value in sorted_degree[:num_values_to_set] else 0 for value in degree]\n",
    "    result_betweenness = [1 if value in sorted_betweenness[:num_values_to_set] else 0 for value in betweenness]\n",
    "    result_clustering = [1 if value in sorted_clustering[:num_values_to_set] else 0 for value in clustering]\n",
    "    result_closeness = [1 if value in sorted_closeness[:num_values_to_set] else 0 for value in closeness]\n",
    "\n",
    "    final_result = [result_degree[i] + result_betweenness[i] + result_clustering[i] + result_closeness[i] for i in range(len(degree))]\n",
    "\n",
    "    if j == 0:\n",
    "        features_array = final_result\n",
    "    else:\n",
    "        features_array = np.vstack((features_array, final_result))\n",
    "\n",
    "    labels.append(label)\n",
    "    if j % 100 == 0:\n",
    "        print(f'----{j} Done)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e34db40-cede-41dd-9820-1fe73909af55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 5],\n",
       "       [1, 3, 5]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.array([1, 3, 5])\n",
    "b = [3, 5, 6]\n",
    "np.vstack((a, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2ec5884-8ce7-4957-ae71-3039b4a89444",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_array\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ecb2f5e-8bef-4f30-94a5-681308fea814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Finished\n",
      "717 MDD & 583 HC\n",
      "Processing the No.1 cross-validation in 10-fold CV\n",
      "----The best parameters: n_estimators=300, max_depth=30 with accuracy of 0.575214\n",
      "Processing the No.2 cross-validation in 10-fold CV\n",
      "----The best parameters: n_estimators=300, max_depth=30 with accuracy of 0.560684\n",
      "Processing the No.3 cross-validation in 10-fold CV\n",
      "----The best parameters: n_estimators=300, max_depth=None with accuracy of 0.569231\n",
      "Processing the No.4 cross-validation in 10-fold CV\n",
      "----The best parameters: n_estimators=300, max_depth=20 with accuracy of 0.560684\n",
      "Processing the No.5 cross-validation in 10-fold CV\n",
      "----The best parameters: n_estimators=200, max_depth=30 with accuracy of 0.570085\n",
      "Processing the No.6 cross-validation in 10-fold CV\n",
      "----The best parameters: n_estimators=300, max_depth=20 with accuracy of 0.584615\n",
      "Processing the No.7 cross-validation in 10-fold CV\n",
      "----The best parameters: n_estimators=300, max_depth=None with accuracy of 0.563248\n",
      "Processing the No.8 cross-validation in 10-fold CV\n",
      "----The best parameters: n_estimators=300, max_depth=20 with accuracy of 0.572650\n",
      "Processing the No.9 cross-validation in 10-fold CV\n",
      "----The best parameters: n_estimators=300, max_depth=10 with accuracy of 0.566667\n",
      "Processing the No.10 cross-validation in 10-fold CV\n",
      "----The best parameters: n_estimators=300, max_depth=20 with accuracy of 0.570940\n",
      "            ACC       SEN       SPE       AUC\n",
      "CV_1   0.530769  0.224138  0.777778  0.537955\n",
      "CV_2   0.569231  0.293103  0.791667  0.581418\n",
      "CV_3   0.538462  0.172414  0.833333  0.483597\n",
      "CV_4   0.507692  0.155172  0.791667  0.531370\n",
      "CV_5   0.538462  0.327586  0.708333  0.534004\n",
      "CV_6   0.507692  0.155172  0.791667  0.457735\n",
      "CV_7   0.538462  0.137931  0.861111  0.532567\n",
      "CV_8   0.576923  0.237288  0.859155  0.543686\n",
      "CV_9   0.576923  0.254237  0.845070  0.620673\n",
      "CV_10  0.561538  0.237288  0.830986  0.539866\n",
      "\n",
      "Average Accuracy: 0.5446\n",
      "Average Sensitivity: 0.2194\n",
      "Average Specificity: 0.8091\n",
      "Average area under ROC curve: 0.5363\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier  # Import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, auc, roc_curve\n",
    "\n",
    "#fpath = 'path/for/feature/file/(csv)'\n",
    "#lpath = 'path/for/label/file/(csv)'\n",
    "seed = 81 # random seed\n",
    "no_folds = 10 # number of folds in out_loop\n",
    "no_nested_folds = 10 # number of folds in nested_loop\n",
    "\n",
    "skf = StratifiedKFold(n_splits=no_folds, shuffle=True, random_state=101)\n",
    "nested_skf = StratifiedKFold(n_splits=no_nested_folds, shuffle=True)\n",
    "param_grid = {'n_estimators': [50, 100, 200, 300], 'max_depth': [None, 10, 20, 30]}  # Modify the parameter grid for RandomForestClassifier\n",
    "eval_metrics = np.zeros((skf.n_splits, 4))\n",
    "print('Loading data ...')\n",
    "# features = np.loadtxt(fpath, delimiter=',')\n",
    "# labels = np.loadtxt(lpath, dtype='int32')\n",
    "\n",
    "features = X\n",
    "labels = y\n",
    "\n",
    "print(f'Finished')\n",
    "print(f'{np.sum(labels == 1)} MDD & {np.sum(labels == 2)} HC')\n",
    "\n",
    "# ROC plotting preparation\n",
    "TPR, AUC = [], []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "for n_cv, (train_ind, test_ind) in enumerate(skf.split(features, labels)):\n",
    "    print('Processing the No.%i cross-validation in %i-fold CV' % (n_cv + 1, skf.n_splits))\n",
    "    x_train, y_train = features[train_ind, ], labels[train_ind, ]\n",
    "    x_test, y_test = features[test_ind, ], labels[test_ind, ]\n",
    "\n",
    "    # Training\n",
    "    init_clf = RandomForestClassifier()\n",
    "    grid = GridSearchCV(init_clf, param_grid, cv=nested_skf, scoring='accuracy', n_jobs=5)\n",
    "    grid.fit(x_train, y_train)\n",
    "    print('----The best parameters: n_estimators=%d, max_depth=%s with accuracy of %f' % (\n",
    "        grid.best_params_['n_estimators'], grid.best_params_['max_depth'], grid.best_score_))\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=grid.best_params_['n_estimators'],\n",
    "                                 max_depth=grid.best_params_['max_depth'])\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predict = clf.predict(x_test)\n",
    "    y_proba = clf.predict_proba(x_test)\n",
    "\n",
    "    # ROC information for each fold\n",
    "    cv_fpr, cv_tpr, cv_thresholds = roc_curve(y_test, y_proba[:, 1], pos_label=2)\n",
    "    cv_auc = auc(cv_fpr, cv_tpr)\n",
    "    interp_tpr = np.interp(mean_fpr, cv_fpr, cv_tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    TPR.append(interp_tpr)\n",
    "    AUC.append(cv_auc)\n",
    "\n",
    "    # Evaluation\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "    cv_accuracy = (tn + tp) / (tn + fp + fn + tp)\n",
    "    cv_sensitivity = tp / (tp + fn)\n",
    "    cv_specificity = tn / (tn + fp)\n",
    "    eval_metrics[n_cv, 0] = cv_accuracy\n",
    "    eval_metrics[n_cv, 1] = cv_sensitivity\n",
    "    eval_metrics[n_cv, 2] = cv_specificity\n",
    "    eval_metrics[n_cv, 3] = cv_auc\n",
    "\n",
    "# reporting model evaluation measures\n",
    "df = pd.DataFrame(eval_metrics)\n",
    "df.columns = ['ACC', 'SEN', 'SPE', 'AUC']\n",
    "df.index = ['CV_' + str(i + 1) for i in range(skf.n_splits)]\n",
    "print(df)\n",
    "print('\\nAverage Accuracy: %.4f' % (eval_metrics[:, 0].mean()))\n",
    "print('Average Sensitivity: %.4f' % (eval_metrics[:, 1].mean()))\n",
    "print('Average Specificity: %.4f' % (eval_metrics[:, 2].mean()))\n",
    "print('Average area under ROC curve: %.4f' % (eval_metrics[:, 3].mean()))\n",
    "\n",
    "# saving ROC plotting information\n",
    "# mean_tpr = np.mean(TPR, axis=0)\n",
    "# mean_tpr[-1] = 1.0\n",
    "# mean_auc = auc(mean_fpr, mean_tpr)\n",
    "# np.savez(fpath + '/../ROC_MTR.npz', tpr=mean_tpr, fpr=mean_fpr, auc=mean_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
